import os
import re
import json
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings  # Atualizado
from langchain_community.vectorstores import FAISS
from openai import OpenAI
from typing import List, Dict, Optional
load_dotenv()
openrouter_key = os.getenv("OPENROUTER_API_KEY")


class OpenRouterClient:
    def __init__(self, model_id: str = "meta-llama/llama-3.3-8b-instruct:free"):
        """
        Cliente para intera√ß√£o com a API OpenRouter
        
        Args:
            model_id: ID do modelo a ser usado (padr√£o: Llama 3 8B gratuito)
        """
        self.model_id = model_id
        self.client = self._initialize_client()
        
    def _initialize_client(self):
        """Configura o cliente OpenAI compat√≠vel com OpenRouter"""
        return OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY"),
        )
        
    def generate_response(self, prompt: str, max_retries: int = 3) -> str:
        """
        Gera resposta para um prompt usando a API OpenRouter
        
        Args:
            prompt: Texto de entrada para o modelo
            max_retries: N√∫mero m√°ximo de tentativas em caso de falha
            
        Returns:
            Resposta textual do modelo
        """
        for attempt in range(max_retries):
            try:
                completion = self.client.chat.completions.create(
                    extra_headers={
                        "HTTP-Referer": "http://localhost:3000",
                        "X-Title": "CV Analyzer",
                    },
                    model=self.model_id,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=2000
                )
                return completion.choices[0].message.content
            except Exception as e:
                if attempt == max_retries - 1:
                    raise RuntimeError(f"Falha ap√≥s {max_retries} tentativas: {str(e)}")
                continue

    def resume_cv(self, cv_text: str) -> str:
        """
        Gera um resumo estruturado do curr√≠culo
        
        Args:
            cv_text: Texto extra√≠do do curr√≠culo
            
        Returns:
            Resumo formatado em Markdown
        """
        prompt = f'''
            Resuma este curr√≠culo em markdown com as se√ß√µes:
            - Nome Completo
            - Experi√™ncia (lista concisa)
            - Habilidades T√©cnicas (destaque as principais)
            - Educa√ß√£o (forma√ß√£o acad√™mica)
            - Idiomas (com n√≠veis de profici√™ncia)
            
            **Curr√≠culo:**
            {cv_text}
            
            **Formato de Sa√≠da (use markdown):**
            ```markdown
            ## Nome Completo
            [nome aqui]
            
            ## Experi√™ncia
            - [Cargo] na [Empresa] ([Per√≠odo])
            ...
            
            ## Habilidades
            - [Habilidade 1]
            ...
            ```
        '''
        return self._clean_response(self.generate_response(prompt))

    def generate_score(self, cv_text: str, job_description: str) -> float:
        """
        Avalia a adequa√ß√£o do curr√≠culo √† vaga (0-10)
        
        Args:
            cv_text: Texto do curr√≠culo
            job_description: Descri√ß√£o da vaga
            
        Returns:
            Pontua√ß√£o num√©rica (0.0 a 10.0)
        """
        prompt = f'''
            Avalie este curr√≠culo para a vaga abaixo e atribua uma pontua√ß√£o de 0 a 10.
            Retorne APENAS o n√∫mero, sem explica√ß√µes ou formata√ß√£o.
            
            **Crit√©rios:**
            - Relev√¢ncia da experi√™ncia (40%)
            - Adequa√ß√£o das habilidades (30%)
            - Forma√ß√£o acad√™mica (15%)
            - Idiomas (15%)
            
            **Vaga:**
            {job_description}
            
            **Curr√≠culo:**
            {cv_text}
        '''
        response = self.generate_response(prompt)
        try:
            score = float(re.search(r"\d+\.?\d*", response).group())
            return min(max(score, 0.0), 10.0)  # Garante que est√° entre 0 e 10
        except:
            return 0.0

    def generate_opinion(self, cv_text: str, job_description: str) -> str:
        """
        Gera uma an√°lise cr√≠tica detalhada do curr√≠culo
        
        Args:
            cv_text: Texto do curr√≠culo
            job_description: Descri√ß√£o da vaga
            
        Returns:
            An√°lise formatada em Markdown
        """
        prompt = f'''
            Analise este curr√≠culo em rela√ß√£o √† vaga e produza um relat√≥rio detalhado
            com os seguintes t√≥picos (formate como Markdown com subt√≠tulos):
            
            ### üîç Pontos Fortes
            - [Liste 3-5 pontos fortes relevantes para a vaga]
            
            ### ‚ö†Ô∏è Pontos de Aten√ß√£o
            - [Mencione 2-3 √°reas que poderiam ser melhoradas]
            
            ### üí° Recomenda√ß√µes
            - [Sugira melhorias espec√≠ficas para o candidato]
            
            **Dados para An√°lise:**
            === VAGA ===
            {job_description}
            
            === CURR√çCULO ===
            {cv_text}
        '''
        return self._clean_response(self.generate_response(prompt))

    def _clean_response(self, text: str) -> str:
        """Remove formata√ß√£o desnecess√°ria da resposta do modelo"""
        if '```markdown' in text:
            return text.split('```markdown')[1].split('```')[0].strip()
        return text.strip()


class CVAnalyserRAG:
    def __init__(self):
        """
        Sistema RAG para an√°lise de curr√≠culos com:
        - Processamento de PDFs
        - Embeddings e busca sem√¢ntica
        - Integra√ß√£o com LLM via OpenRouter
        """
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-mpnet-base-v2",
            model_kwargs={'device': 'cpu'}
        )
        self.vectorstore = None
        self.llm = OpenRouterClient()

    def load_pdfs(self, pdf_folder: str) -> None:
        """
        Carrega e processa curr√≠culos em PDF de uma pasta
        
        Args:
            pdf_folder: Caminho para a pasta com os PDFs
        """
        if not os.path.exists(pdf_folder):
            raise ValueError(f"Pasta n√£o encontrada: {pdf_folder}")
            
        documents = []
        for filename in os.listdir(pdf_folder):
            if filename.endswith(".pdf"):
                path = os.path.join(pdf_folder, filename)
                try:
                    loader = PyPDFLoader(path)
                    pages = loader.load()
                    for page in pages:
                        page.metadata["source"] = filename
                    documents.extend(pages)
                except Exception as e:
                    print(f"Erro ao processar {filename}: {str(e)}")
        
        if not documents:
            raise ValueError("Nenhum PDF v√°lido encontrado na pasta")
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        splits = text_splitter.split_documents(documents)
        self.vectorstore = FAISS.from_documents(splits, self.embeddings)

    def analyse_candidates(self, job_description: str, top_k: int = 5) -> List[Dict]:
        """
        Analisa os curr√≠culos mais relevantes para uma vaga
        
        Args:
            job_description: Descri√ß√£o textual da vaga
            top_k: N√∫mero de curr√≠culos para retornar
            
        Returns:
            Lista de dicion√°rios com resultados da an√°lise
        """
        if not self.vectorstore:
            raise ValueError("Nenhum curr√≠culo carregado. Use load_pdfs() primeiro.")
            
        if not job_description.strip():
            raise ValueError("A descri√ß√£o da vaga n√£o pode estar vazia")
            
        docs = self.vectorstore.similarity_search(job_description, k=top_k)
        
        results = []
        for doc in docs:
            try:
                cv_content = doc.page_content
                results.append({
                    "file": doc.metadata["source"],
                    "score": self.llm.generate_score(cv_content, job_description),
                    "summary": self.llm.resume_cv(cv_content),
                    "opinion": self.llm.generate_opinion(cv_content, job_description),
                    "content": cv_content[:500] + "..."
                })
            except Exception as e:
                print(f"Erro ao analisar {doc.metadata['source']}: {str(e)}")
        
        return sorted(results, key=lambda x: x["score"], reverse=True)


# Exemplo de uso (para testes)
if __name__ == "__main__":
    analyser = CVAnalyserRAG()
    
    # Exemplo com PDFs locais
    pdf_folder = "cv_pdfs"  # Pasta com curr√≠culos
    if os.path.exists(pdf_folder):
        analyser.load_pdfs(pdf_folder)
        
        job_desc = """
        Desenvolvedor Python S√™nior
        Requisitos:
        - 5+ anos com Python
        - Experi√™ncia com Django/Flask
        - Conhecimento em bancos de dados SQL/NoSQL
        - Ingl√™s t√©cnico
        """
        
        results = analyser.analyse_candidates(job_desc)
        print(f"Melhor candidato: {results[0]['file']} ({results[0]['score']}/10)")